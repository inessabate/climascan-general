# Climascan Data Pipeline

Este repositorio implementa un pipeline de datos diseÃ±ado para construir un modelo de predicciÃ³n de riesgo ante eventos climÃ¡ticos extremos. El proyecto sigue una estructura basada en el estÃ¡ndar [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/), adaptada a un flujo de trabajo con Delta Lake, datos meteorolÃ³gicos y datos de siniestros.

---
## ğŸ¯ Objetivo del Repositorio

Este repositorio tiene como objetivo **recoger, procesar y almacenar datos** relacionados con eventos climÃ¡ticos extremos y siniestros asociados, con el fin de construir un conjunto de datos limpio y estructurado que sirva como base para el entrenamiento de modelos de predicciÃ³n de riesgo.

El flujo general del pipeline incluye:

- ğŸ“¥ **Ingesta** de datos meteorolÃ³gicos desde APIs y datos de siniestros desde ficheros Excel.
- ğŸ§¹ **Procesamiento y transformaciÃ³n** de los datos para limpieza, enriquecimiento y creaciÃ³n de variables.
- ğŸ’¾ **Almacenamiento** en formato Delta Lake para consultas eficientes y uso posterior en modelado predictivo.
---


## ğŸ“ Estructura del Proyecto

```plaintext
Climascan-data-pipeline/
â”‚
â”œâ”€â”€ data/                      # Almacenamiento local de datos
â”‚   â”œâ”€â”€ raw/                   # Datos sin procesar (por ejemplo, Excels originales o respuestas JSON)
â”‚   â”œâ”€â”€ interim/               # Datos parcialmente procesados o fusionados
â”‚   â”œâ”€â”€ processed/             # Datos listos para entrenar modelos (features)
â”‚   â””â”€â”€ delta/                 # Tablas en formato Delta Lake
â”‚       â”œâ”€â”€ claims/            # Datos de siniestros transformados en Delta
â”‚       â””â”€â”€ meteo/             # Datos meteorolÃ³gicos transformados en Delta
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter/Databricks notebooks de exploraciÃ³n y EDA
â”‚
â”œâ”€â”€ src/                       # CÃ³digo fuente del pipeline
â”‚   â”œâ”€â”€ ingestion/             # Scripts para cargar datos desde APIs y Excels
â”‚   â”œâ”€â”€ processing/            # Transformaciones, limpiezas y feature engineering
â”‚   â””â”€â”€ utils/                 # Funciones auxiliares (creaciÃ³n de sesiÃ³n Spark, logs, helpers)
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml            # ParÃ¡metros globales del pipeline (rutas, fechas, etc.)
â”‚
â”œâ”€â”€ tests/                     # Pruebas unitarias del pipeline
â”‚
â”œâ”€â”€ requirements.txt           # Dependencias del entorno
â”œâ”€â”€ .env                       # Variables de entorno (no versionadas)
â”œâ”€â”€ .gitignore                 # ExclusiÃ³n de carpetas como `.idea/`, `venv/`, `.env`, etc.
â””â”€â”€ README.md                  # Este archivo

```
